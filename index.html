<!doctype html>
<html lang="ar">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Ù…Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ - Google Speech-to-Text</title>
  <link href="https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;700&display=swap" rel="stylesheet">
  <style>
    body { font-family: 'Cairo', sans-serif; background: linear-gradient(135deg,#74ABE2,#5563DE); color:#fff; min-height:100vh; display:flex; align-items:center; justify-content:center; margin:0; }
    .card { background: rgba(255,255,255,0.07); padding:28px; border-radius:14px; width:920px; max-width:95%; box-shadow:0 8px 30px rgba(0,0,0,0.25); }
    h1 { margin:0 0 10px 0; font-size:1.6rem; }
    p.lead { margin:0 0 18px 0; opacity:0.95; }
    .controls { display:flex; gap:12px; flex-wrap:wrap; align-items:center; }
    button { background:#fff; color:#222; border:none; padding:12px 18px; border-radius:10px; cursor:pointer; font-weight:600; }
    button.secondary { background:transparent; color:#fff; border:1px solid rgba(255,255,255,0.2); }
    #status { margin-left:8px; font-size:0.95rem; opacity:0.95; }
    #transcript { margin-top:18px; background:rgba(255,255,255,0.06); padding:14px; border-radius:10px; min-height:140px; white-space:pre-wrap; overflow:auto; }
    .small { font-size:0.9rem; opacity:0.9; }
    .row { display:flex; gap:12px; align-items:center; margin-top:12px; }
    .right { margin-left:auto; }
    footer { margin-top:14px; font-size:0.85rem; opacity:0.9; }
    a.link { color:#ffe; text-decoration:underline; }
  </style>
</head>
<body>
  <div class="card" role="main">
    <h1>ğŸ¤ Ù…Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ (Google Speech-to-Text)</h1>
    <p class="lead">Ø§Ø¶ØºØ· "Ø§Ø¨Ø¯Ø£" Ù„Ù„ØªØ³Ø¬ÙŠÙ„ØŒ Ø«Ù… Ø§Ø¶ØºØ· "Ø¥ÙŠÙ‚Ø§Ù" Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ø°ÙŠ Ø³ÙŠØ³ØªØ¯Ø¹ÙŠ Google Speech-to-Text ÙˆÙŠØ¹ÙŠØ¯ Ø§Ù„Ù†Øµ.</p>

    <div class="controls">
      <button id="startBtn">ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„</button>
      <button id="stopBtn" class="secondary" disabled>â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù</button>
      <button id="copyBtn" class="secondary" disabled>ğŸ“‹ Ù†Ø³Ø® Ø§Ù„Ù†Øµ</button>
      <div id="status" class="small">Ø­Ø§Ù„Ø©: Ø¬Ø§Ù‡Ø²</div>
    </div>

    <div id="transcript" aria-live="polite">Ù„Ù… ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ Ø£ÙŠ ÙƒÙ„Ø§Ù… Ø¨Ø¹Ø¯...</div>

    <div class="row">
      <div class="small">Ù…Ù„Ø§Ø­Ø¸Ø©: Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ù…Ø­Ù„ÙŠ. Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª - Ø±Ø§Ø¬Ø¹ Ù…Ù„Ù README.</div>
      <div class="right"><a class="link" href="README.md" target="_blank">Ø¹Ø±Ø¶ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø´Ø±</a></div>
    </div>

    <footer>ØªØ¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (ar-SA) Ø¨Ø´ÙƒÙ„ Ø§ÙØªØ±Ø§Ø¶ÙŠ. ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ± Ø§Ù„Ù„ØºØ© ÙÙŠ Ø§Ù„Ù…Ù„Ù server.js Ø£Ùˆ ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­.</footer>
  </div>

  <script>
  // Recorder using MediaRecorder to capture audio as WAV-like blob (webm/ogg may be used by browser).
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const copyBtn = document.getElementById('copyBtn');
  const statusEl = document.getElementById('status');
  const transcriptEl = document.getElementById('transcript');

  let mediaRecorder;
  let audioChunks = [];

  function setStatus(s){
    statusEl.textContent = 'Ø­Ø§Ù„Ø©: ' + s;
  }

  startBtn.addEventListener('click', async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioChunks = [];
      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstart = () => {
        setStatus('Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¬Ø§Ø±ÙŠ...');
        startBtn.disabled = true;
        stopBtn.disabled = false;
        transcriptEl.textContent = 'Ø§Ù„ØªØ³Ø¬ÙŠÙ„...';
      };
      mediaRecorder.start();
    } catch (err) {
      setStatus('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø°Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†');
      console.error(err);
    }
  });

  stopBtn.addEventListener('click', async () => {
    if (!mediaRecorder) return;
    mediaRecorder.onstop = async () => {
      setStatus('ÙŠØªÙ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØª ÙˆØ¥Ø±Ø³Ø§Ù„Ù‡...');
      startBtn.disabled = false;
      stopBtn.disabled = true;

      const blob = new Blob(audioChunks, { type: audioChunks[0]?.type || 'audio/webm' });
      // convert to base64
      const base64 = await blobToBase64(blob);
      // send to backend
      try {
        const resp = await fetch('/speech-to-text', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ audio: base64.split(',')[1], mimeType: blob.type })
        });
        if (!resp.ok) throw new Error('Server error: ' + resp.status);
        const data = await resp.json();
        transcriptEl.textContent = data.text || '[Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù†Øµ]';
        copyBtn.disabled = false;
        setStatus('Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„');
      } catch (err) {
        console.error(err);
        setStatus('Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„');
        transcriptEl.textContent = 'âš ï¸ Ø®Ø·Ø£: ' + err.message;
      }
    };
    mediaRecorder.stop();
  });

  copyBtn.addEventListener('click', async () => {
    try {
      await navigator.clipboard.writeText(transcriptEl.textContent);
      setStatus('Ø§Ù„Ù†Øµ Ù†ÙØ³Ø® Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ¸Ø©');
    } catch (e) {
      setStatus('ÙØ´Ù„ Ù†Ø³Ø® Ø§Ù„Ù†Øµ');
    }
  });

  function blobToBase64(blob){
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result);
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }
  </script>
</body>
</html>
